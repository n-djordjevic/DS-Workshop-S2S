{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Machine Learning!<br>\n",
    "As Deep Learning and AI, Machine Learning is currently a buzzword in the news and media. Many people praise Machine Learning, without even knowing what it is.<br>\n",
    "Wikipedia defines Machine Learning as: \"a subset of Artificial Intelligence in the field of Computer Science that often uses statistical techniques to give computers the ability to \"learn\" with data, without being explicitly programmed.\" As when you were a kid, you needed to see a handful of cats in order to say with certainty that something is a cat. Same is with computers. Before the computer can say something is a cat, we show it several examples of what a cat is, instead of programming the rules of what a cat looks like.<br>\n",
    "Of course, this was more of a problem in the Deep Learning section, but there are some tasks where Machine Learning specifically is useful:<br>\n",
    "<ul><li>classification - predicting which class some instance belongs to</li>\n",
    "    <li>regression - predicting a numerical target feature</li>\n",
    "    <li>clustering - grouping similar instances into the same groups/clusters</li>\n",
    "    <li>anomaly detection - detecting which instances are greatly different than the rest</li>\n",
    "    <li>recommender systems - based on the history of a user, predict what he/she will like</li>\n",
    "</ul>and so much more...<br><br>\n",
    "Machine Learning can also be divided by the type of learning, but the main two are:\n",
    "<ul><li>supervised - when the target feature is known before we predict it</li>\n",
    "    <li>unsupervised - when the target feature isn't known</li></ul><br>\n",
    "In this section, we'll be doing a binary classification, which is supervised learning. We'll use the same data as before.<br>\n",
    "The new library, we'll be trying out is <a href='https://scikit-learn.org/stable/index.html'>sci-kit learn</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>...</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128        415  382-4657         no        yes   \n",
       "1    OH             107        415  371-7191         no        yes   \n",
       "2    NJ             137        415  358-1921         no         no   \n",
       "3    OH              84        408  375-9999        yes         no   \n",
       "4    OK              75        415  330-6626        yes         no   \n",
       "\n",
       "   VMail Message  Day Mins  Day Calls  Day Charge  ...  Eve Calls  Eve Charge  \\\n",
       "0             25     265.1        110       45.07  ...         99       16.78   \n",
       "1             26     161.6        123       27.47  ...        103       16.62   \n",
       "2              0     243.4        114       41.38  ...        110       10.30   \n",
       "3              0     299.4         71       50.90  ...         88        5.26   \n",
       "4              0     166.7        113       28.34  ...        122       12.61   \n",
       "\n",
       "   Night Mins  Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "0       244.7           91         11.01       10.0           3         2.70   \n",
       "1       254.4          103         11.45       13.7           3         3.70   \n",
       "2       162.6          104          7.32       12.2           5         3.29   \n",
       "3       196.9           89          8.86        6.6           7         1.78   \n",
       "4       186.9          121          8.41       10.1           3         2.73   \n",
       "\n",
       "   CustServ Calls  Churn?  \n",
       "0               1   False  \n",
       "1               1   False  \n",
       "2               0   False  \n",
       "3               2   False  \n",
       "4               3   False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/churn.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can jump straight into Machine Learning, we need to preprocess our data. Why? Because Machine Learning algorithms can't use textual data, meaning our yes/no features are useless. Maybe we have some missing values which need to be filled before we can use them, and so on.<br>\n",
    "Firstly, we're going to turn those yes/no features into zeroes and ones and turn the `Phone` feature into an index column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382-4657</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371-7191</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358-1921</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375-9999</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330-6626</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         State  Account Length  Area Code  Int'l Plan  VMail Plan  \\\n",
       "Phone                                                               \n",
       "382-4657    KS             128        415           0           1   \n",
       "371-7191    OH             107        415           0           1   \n",
       "358-1921    NJ             137        415           0           0   \n",
       "375-9999    OH              84        408           1           0   \n",
       "330-6626    OK              75        415           1           0   \n",
       "\n",
       "          VMail Message  Day Mins  Day Calls  Day Charge  Eve Mins  Eve Calls  \\\n",
       "Phone                                                                           \n",
       "382-4657             25     265.1        110       45.07     197.4         99   \n",
       "371-7191             26     161.6        123       27.47     195.5        103   \n",
       "358-1921              0     243.4        114       41.38     121.2        110   \n",
       "375-9999              0     299.4         71       50.90      61.9         88   \n",
       "330-6626              0     166.7        113       28.34     148.3        122   \n",
       "\n",
       "          Eve Charge  Night Mins  Night Calls  Night Charge  Intl Mins  \\\n",
       "Phone                                                                    \n",
       "382-4657       16.78       244.7           91         11.01       10.0   \n",
       "371-7191       16.62       254.4          103         11.45       13.7   \n",
       "358-1921       10.30       162.6          104          7.32       12.2   \n",
       "375-9999        5.26       196.9           89          8.86        6.6   \n",
       "330-6626       12.61       186.9          121          8.41       10.1   \n",
       "\n",
       "          Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
       "Phone                                                      \n",
       "382-4657           3         2.70               1       0  \n",
       "371-7191           3         3.70               1       0  \n",
       "358-1921           5         3.29               0       0  \n",
       "375-9999           7         1.78               2       0  \n",
       "330-6626           3         2.73               3       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Int\\'l Plan'] = df['Int\\'l Plan'].map({'yes': 1, 'no': 0})\n",
    "df['VMail Plan'] = df['VMail Plan'].map({'yes': 1, 'no': 0})\n",
    "df['Churn?'] = df['Churn?'].astype('int64')\n",
    "df.set_index(df['Phone'], inplace=True)\n",
    "df.drop(['Phone'], axis = 1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `State` feature has more than 50 unique values and `Area Code` three, for now, we'll just drop them. Of course, there are certain methodologies for handling such data, but that is out of scope for this particular section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['State'], axis=1, inplace=True)\n",
    "df.drop(['Area Code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll need to split our dataset into target data and data our model will use to predict that target. That's the format Machine Learning algorithms accept for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>VMail Message</th>\n",
       "      <th>Day Mins</th>\n",
       "      <th>Day Calls</th>\n",
       "      <th>Day Charge</th>\n",
       "      <th>Eve Mins</th>\n",
       "      <th>Eve Calls</th>\n",
       "      <th>Eve Charge</th>\n",
       "      <th>Night Mins</th>\n",
       "      <th>Night Calls</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phone</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382-4657</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371-7191</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358-1921</th>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375-9999</th>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330-6626</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Account Length  Int'l Plan  VMail Plan  VMail Message  Day Mins  \\\n",
       "Phone                                                                       \n",
       "382-4657             128           0           1             25     265.1   \n",
       "371-7191             107           0           1             26     161.6   \n",
       "358-1921             137           0           0              0     243.4   \n",
       "375-9999              84           1           0              0     299.4   \n",
       "330-6626              75           1           0              0     166.7   \n",
       "\n",
       "          Day Calls  Day Charge  Eve Mins  Eve Calls  Eve Charge  Night Mins  \\\n",
       "Phone                                                                          \n",
       "382-4657        110       45.07     197.4         99       16.78       244.7   \n",
       "371-7191        123       27.47     195.5        103       16.62       254.4   \n",
       "358-1921        114       41.38     121.2        110       10.30       162.6   \n",
       "375-9999         71       50.90      61.9         88        5.26       196.9   \n",
       "330-6626        113       28.34     148.3        122       12.61       186.9   \n",
       "\n",
       "          Night Calls  Night Charge  Intl Mins  Intl Calls  Intl Charge  \\\n",
       "Phone                                                                     \n",
       "382-4657           91         11.01       10.0           3         2.70   \n",
       "371-7191          103         11.45       13.7           3         3.70   \n",
       "358-1921          104          7.32       12.2           5         3.29   \n",
       "375-9999           89          8.86        6.6           7         1.78   \n",
       "330-6626          121          8.41       10.1           3         2.73   \n",
       "\n",
       "          CustServ Calls  \n",
       "Phone                     \n",
       "382-4657               1  \n",
       "371-7191               1  \n",
       "358-1921               0  \n",
       "375-9999               2  \n",
       "330-6626               3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Machine Learning<br>\n",
    "In this section, we'll cover some of the most used Machine Learning algorithms such as Logistic Regression, k Nearest Neighbors and Decision Tree. All of those algorithms can be found in the `sci-kit learn` library (sklearn for short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stopwolf/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of fit method, our model learns from the data we provided so it can predict new targets for the new data we give it. The output of the fit model, as can be seen above, is a model with all of its hyperparameters. <b>Hyperparameters</b> are settings of the model we can tweak. By doing so, we can get even better final results. Before we get into measuring the \"goodness\" of our models, let's train a couple more. K Nearest Neighbor model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the Decision Tree model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluation<br>\n",
    "\n",
    "But how good are these models we created?<br>\n",
    "In this section, we'll cover some of the most popular evaluation metrics like `accuracy`, `precision`, `recall` and `confusion matrix`. Since confusion matrix combines all of these, that'll be our starting point.<br>\n",
    "<img src='img/confusion_matrix.png'><br>\n",
    "We can use the same name function from `sci-kit learn` library to plot the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'True')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "ax = plt.subplot()\n",
    "sns.heatmap(confusion_matrix(y_true=y, y_pred=model_lr.predict(X)), ax=ax, annot = True)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeroes ,in this case, represent non-churners, and ones represent churners. Straight from this plot, we can see that the most common group is the non-churner group {row 0 and column 0}.<br>\n",
    "But, what else can we derive from this confusion matrix? The answer is almost every other evaluation metric!<br>\n",
    "You can use the above image of the confusion matrix, to check if these formulas are correct:<br><br>\n",
    "The accuracy score: $ accuracy\\ =\\ \\frac{TP+TN}{TN+FN+FP+TP} $<br>\n",
    "The precision score: $ precision\\ =\\ \\frac{TP}{TP+FP} $<br>\n",
    "The recall score: $ recall\\ =\\ \\frac{TP}{TP+FN}$<br>\n",
    "\"But what do these mean? And when shoud I use each of these?\", you might be wondering. Let's investigate this.<br><br>\n",
    "<b>Accuracy</b> is the most standard metric, but also one of the worst ones because it only looks at correctly classified instances. We ignore False Positives and False Negatives, which might be more important for our specific problem.<br>\n",
    "For an example, if we were creating a spam detection app, if we say something IS spam and it wasn't, we're making a bigger mistake than the other way around - if we say something isn't spam and it actually is. That means, False Positive values are more important, so our metric should be appropriate for the spam detection problem. From the above formulas, we can see that <b>precision</b> uses FP values, which is why that would we a good metric for spam detection.<br><br>\n",
    "In the real world, that case is really rare. We come across more examples where we should optimize our models for False Negative values. If we were predicting brain tumour, if we say this patient doesn't have a tumour, but he actually has one, our actions may result in that patient's death. But if we say he has a tumour, but he doesn't, he won't die from the treatment. In this case, we should optimize the <b>recall</b> score.<br>\n",
    "Here's another graphic depiction of precision and recall:<br>\n",
    "<img src='img/PrecisionRecall.svg.png'><br>\n",
    "So, let's check how good our models did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = model_lr.predict(X)\n",
    "y_pred_knn = model_knn.predict(X)\n",
    "y_pred_tree = model_tree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:(0.8616861686168616, 0.5743243243243243, 0.17598343685300208)\n",
      "K Nearest Neighbors:(0.8970897089708971, 0.8365384615384616, 0.36024844720496896)\n",
      "Decision Trees:(1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "print(f'Logistic Regression:{accuracy_score(y, y_pred_lr), precision_score(y, y_pred_lr), recall_score(y, y_pred_lr)}')\n",
    "print(f'K Nearest Neighbors:{accuracy_score(y, y_pred_knn), precision_score(y, y_pred_knn), recall_score(y, y_pred_knn)}')\n",
    "print(f'Decision Trees:{accuracy_score(y, y_pred_tree), precision_score(y, y_pred_tree), recall_score(y, y_pred_tree)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, it would seem that the `Decision Tree` model is the best! And not only best, but perfect!!<br>\n",
    "Actually, sorry to break it to you, but that's not the case... This is called <b>overfitting</b>. It happens when our model learns every detail of our data and does a perfectly good job, but when new data arrives, it becomes terrible. And of course, there's a way to prevent this, using one of the most common practises which we skipped until now: train/test splitting.<br><br>\n",
    "Splitting data into three sets is really common practise tool in Data Science. We split our original dataset into: train, development and test sets. As the names suggest, we train our model on the training data, develop and improve it using development data, and at the end we look how it performs on the test set.<br>\n",
    "If we have less than 1.000.000 instances we should divide our dataset into sections of 80/10/10.<br>\n",
    "If we have more than that, we can freely split into sections of 98/1/1.<br>\n",
    "Even though there are three sets in that convention, we use only training and test sets. In our case, test is the development set.<br><br>\n",
    "Let's split our dataset, and repeat our training and evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stopwolf/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression()\n",
    "\n",
    "model_lr.fit(X_train, y_train)\n",
    "y_hat_lr = model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "\n",
    "model_knn.fit(X_train, y_train)\n",
    "y_hat_knn = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tree = DecisionTreeClassifier()\n",
    "\n",
    "model_tree.fit(X_train, y_train)\n",
    "y_hat_tree = model_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:(0.854916067146283, 0.5142857142857142, 0.14754098360655737)\n",
      "K Nearest Neighbors:(0.8741007194244604, 0.660377358490566, 0.28688524590163933)\n",
      "Decision Trees:(0.9148681055155875, 0.6917293233082706, 0.7540983606557377)\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression:{accuracy_score(y_test, y_hat_lr), precision_score(y_test, y_hat_lr), recall_score(y_test, y_hat_lr)}')\n",
    "print(f'K Nearest Neighbors:{accuracy_score(y_test, y_hat_knn), precision_score(y_test, y_hat_knn), recall_score(y_test, y_hat_knn)}')\n",
    "print(f'Decision Trees:{accuracy_score(y_test, y_hat_tree), precision_score(y_test, y_hat_tree), recall_score(y_test, y_hat_tree)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our `Decision Tree` isn't perfect anymore, but now, it's more useful. It also has higher precision AND recall scores than two other models.<br>\n",
    "***\n",
    "<b>Additional Resources:</b>\n",
    "<ul><li>in-depth, fully mathematical description of algorithms we used here can be found <a href='https://www.dropbox.com/s/qiq2c85cle9ydb6/Chapter3.pdf?dl=0'>here</a></li>\n",
    "    <li>sci-kit learn <a href='https://scikit-learn.org/stable/documentation.html'>documentation</a></li></ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
